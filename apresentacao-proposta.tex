\documentclass[11pt]{beamer}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{booktabs}
\usepackage[retainorgcmds]{IEEEtrantools}
\usepackage{subfigure}

% Pacotes para usar todonotes como default
\usepackage{xkeyval}
\usepackage{todonotes}
\presetkeys{todonotes}{inline}{}


\usetheme{AnnArbor}
\usecolortheme{beaver}
\begin{document}
\author{Marcelo Ruas e Alexandre Street}
\title{Scenario generation for nongaussian time series via Quantile Regression}
%\subtitle{}
	%\logo{}
	%\institute{}
	%\date{}
	%\subject{}
	%\setbeamercovered{transparent}
	%\setbeamertemplate{navigation symbols}{}
\begin{frame}[plain]
\maketitle
\end{frame}


\input{apre-introduction}
\input{apre-quantile-regression}




\begin{frame}{ADALASSO for quantile regression}
	

\small
When estimating the ADALASSO for quantile regression, we show a few adaptations and extensions of the original method. The full process consists of two steps, each consisting of a LASSO estimation:
\begin{itemize}
	\item \textbf{First step:} First LASSO regularization
	\[
\underset{\beta_{0j},\beta_j}{\text{min}} \sum_{j \in J} \left( \sum_{t\in T}\rho_{\alpha_j}(y_{t}-(\beta_{0j} + \beta_j^T x_t)) + \lambda\  \sum_{p \in P} \mid  \beta_{pj} \mid \right)  + \gamma \sum_{j \in J'} (D2_{pj}^+ + D2_{pj}^-),
\]
	
	\item \textbf{Second step:} Two forms of using initial estimation to determine $w_{pj}$ are:
	\begin{enumerate}
		\item $w_{pj} = 1/ \beta_{pj}$.
		\item $w_{pj} = 1/ (\beta_{pj} \parallel \beta_j \parallel_1)$,
	\end{enumerate}
	The weights $w_j$ are input to a second-stage Lasso estimation:
		\[
	\underset{\beta_{0j},\beta_j}{\text{min}} \sum_{j \in J} \left( \sum_{t\in T}\rho_{\alpha_j}(y_{t}-(\beta_{0j} + \beta_j^T x_t)) + \lambda\  \sum_{p \in P} w_{pj}^\delta \mid  \beta_{pj} \mid \right) + \gamma \sum_{j \in J'} (D2_{pj}^+ + D2_{pj}^-),
	\]
	where $\delta$ is an exponential parameter, normally set to 1.
	
\end{itemize}



\end{frame}

\section{Estimation and Evaluation}\label{estimation-and-evaluation}

\begin{frame}{Evaluation Metrics}

\begin{itemize}

\item
We use a performance measurement which emphasizes the correctness of
each quantile. For each probability \(\alpha \in A\), a loss function
is defined by
\[L_\alpha(q)= \sum_{t\in T}\rho_{\alpha}(y_{t}-q_{\alpha}(x_t)).\]
The loss score \(\mathcal{L}\), which is the chosen evaluation metric
to optimize, aggregates the score function over all elements of \(A\):
\[\mathcal{L}= \frac{1}{|A|}\sum_{\alpha \in A}L_\alpha(q).\]
\end{itemize}

\end{frame}

\begin{frame}{Time-series Cross-Validation}

\begin{figure}
\centering
\includegraphics[width=0.9\linewidth]{Images/Cross-validation-scheme}
\caption{$\mathcal{K}$-fold CV and $\mathcal{K}$-fold with non-dependent data. Observations in blue are used to estimation and in orange for evaluation. Note that non-dependent data doesn't use all dataset in each fold.}
\label{fig:cross-validation-scheme}
\end{figure}

\end{frame}

\begin{frame}{Time-series Cross-Validation}

\begin{itemize}

\item
The CV score is given by the sum of the loss function for each fold.
The optimum value of \(t\) in this criteria is the one that minimizes
the CV score: \[
\theta^* = \text{argmin}_\theta CV(\theta) = \sum_{k \in \mathcal{K}} \sum_{\alpha \in A} L_\alpha(q).
\]
\item
To optimize CV function in \(\theta\), we use the Nelder-Mead
algorithm, which is a known and widely used algorithm for black-box
optimization.
\end{itemize}

\end{frame}

\section{Nonparametric model}\label{nonparametric-model}

\begin{frame}{Nonparametric model}

\[
\hat{Q}_{Y|X}(\alpha,\cdot)\quad\in\quad  \underset{q(\cdot)\in\mathcal{Q}}{\text{arg min}}\, L_\alpha(q) = \sum_{t\in T}\rho_{\alpha}(y_{t}-q(x_t)),
\]

\begin{itemize}
\item
On nonparametric models, \(q_\alpha\) belongs to a space of limited
second derivative function \(\mathcal{Q}\).
\item
The \(\alpha\)-quantile function is flexible enough to capture
nonlinearities on the quantile function.
\end{itemize}

\end{frame}

\begin{frame}{Nonparametric model - Formulation}


\begin{IEEEeqnarray*}{llr}
\min_{q_{j t},\varepsilon^+_{t}, \varepsilon_t^-, \xi_t} \sum_{j \in J} \sum_{t \in T'}\left(\alpha_j \varepsilon_{t j }^{+}+(1-\alpha_j)\varepsilon_{t j }^{-}\right) + \lambda \sum_{t \in T'}\xi_{t j } \span \span \nonumber \\
s.t. \qquad & \varepsilon_{t}^{+}-\varepsilon_{t j }^{-}=y_{t}-q_{t j }, & \forall t \in T',\forall j \in J,\\
& D^{1}_{t j }=\frac{q_{j t+1}-q_{j t}}{x_{t+1}-x_{t}}, 
& \qquad\forall t \in T',\forall j \in J,\\   
& D^{2}_{t j }:=\frac{\left(\frac{q_{j t+1}-q_{j t}}{x_{t+1}-x_{t}}\right)-\left(\frac{q_{j t}-q_{j t-1}}{x_{t}-x_{t-1}}\right)}{x_{t+1}-2x_{t} + x_{t-1}} \span\\
& \xi_{t j}\geq D^2_{t j }, & \qquad\forall t \in T',\forall j \in J,\\
& \xi_{t j}\geq-D^2_{t j}, & \qquad\forall t \in T',\forall j \in J,\\
& \varepsilon_{t j}^{+},\varepsilon_{t j}^{-}, \xi_{t j}\geq0, & \qquad\forall t \in T',\forall j \in J,\\
& q_{t j} \leq q_{t,j+1}, & \qquad \forall t \in T', \forall j \in J,\nonumber \\  
\end{IEEEeqnarray*}


\end{frame}

\begin{frame}{Nonparametric vs.~Linear Model}

\begin{itemize}

\item
The nonparametric approach is more flexible to capture
heteroscedasticity.
\end{itemize}

\begin{figure}
\centering
\begin{minipage}[t]{\linewidth}
\centering
\begin{minipage}[t]{0.45\linewidth}
\centering     \includegraphics[width=\textwidth]{Images/icaraizinho-quantile-linear}
\end{minipage}
\begin{minipage}[t]{0.45\linewidth}
\centering     \includegraphics[width=\textwidth]{Images/icaraizinho-quantile-nonpar-lambda30}
\end{minipage}
\end{minipage}
\caption{Estimated quantile functions, for different values of $y_{t-1}$. On the left using a linear model and using a nonparametric approach on the right.}
\label{fig:quantiles-vs-xt}
\end{figure}

\end{frame}

\begin{frame}{Control of smoothing parameter}

\begin{itemize}

\item
This flexibility might lead to overfitting, if we don't select a
proper smoothing parameter.
\end{itemize}

\begin{figure}
\centering
\begin{minipage}[t]{\linewidth}
\centering
\begin{minipage}[t]{0.45\linewidth}
\centering     \includegraphics[width=\textwidth]{Images/icaraizinho-crossing-01}
\subcaption{$\lambda = 0.1$}
\end{minipage}
\begin{minipage}[t]{0.45\linewidth}
\centering     \includegraphics[width=\textwidth]{Images/icaraizinho-crossing-3}
\subcaption{$\lambda = 3$}
\end{minipage}
\end{minipage}
\end{figure}

\end{frame}

\begin{frame}{Control of smoothing parameter}

\begin{figure}
\centering
\begin{minipage}[t]{\linewidth}
\centering
\begin{minipage}[t]{0.45\linewidth}
\centering     \includegraphics[width=\textwidth]{Images/icaraizinho-crossing-10}
\subcaption{$\lambda = 10$}
\end{minipage}
\begin{minipage}[t]{0.45\linewidth}
\centering     \includegraphics[width=\textwidth]{Images/icaraizinho-crossing-200}
\subcaption{$\lambda = 100$}
\end{minipage}
\end{minipage}
\end{figure}

\begin{itemize}

\item
On the limit, when \(\lambda \rightarrow \infty\), the nonparametric
model approaches a linear model.
\end{itemize}

\end{frame}

\begin{frame}{Present issues}

\begin{itemize}

\item
Difficult interpolation when \(x_t\) has dimension greater than 1.
\item
Control of smoothing parameter
\end{itemize}

\end{frame}

\section{Final}\label{final}


% Inserir slides com toda a bibliografia

\begin{frame}[allowframebreaks]
        \tiny
        \frametitle{References}
        \bibliographystyle{amsalpha}
          \bibliography{QR,Thesis,Bibhenriquinho}
\end{frame}

\end{document}
